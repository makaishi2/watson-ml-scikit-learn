{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 日本語Word2Vecサンプル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 青空文庫より「三四郎」をダウンロードし整形するまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルダウンロード、解凍\n",
    "!wget http://www.aozora.gr.jp/cards/000148/files/794_ruby_4237.zip\n",
    "!unzip 794_ruby_4237.zip\n",
    "!ls -l sanshiro.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイル読込み、内部表現化\n",
    "f = open('sanshiro.txt')\n",
    "text_sjis = f.read()\n",
    "f.close()\n",
    "text = text_sjis.decode('sjis')\n",
    "\n",
    "# ファイル整形\n",
    "import re\n",
    "# ヘッダ部分の除去\n",
    "text = re.split(u'\\-{5,}',text)[2]\n",
    "# フッタ部分の除去\n",
    "text = re.split(u'底本：',text)[0]\n",
    "# | の除去\n",
    "text = text.replace(u'|', u'')\n",
    "# ルビの削除\n",
    "text = re.sub(u'《.+?》', u'', text)\n",
    "# 入力注の削除\n",
    "text = re.sub(u'［＃.+?］', u'',text)\n",
    "# 空行の削除\n",
    "text = re.sub(u'\\n\\n', '\\n', text) \n",
    "text = re.sub(u'\\r', '', text)\n",
    "\n",
    "# 整形結果確認\n",
    "\n",
    "# 頭の100文字の表示 \n",
    "print text[:100]\n",
    "# 見やすくするため、空行 \n",
    "print\n",
    "print\n",
    "# 後ろの100文字の表示 \n",
    "print text[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 Janomeを使い三四郎テキストから単語リストを生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Janomeのインストール\n",
    "!pip install janome\n",
    "\n",
    "# Janomeのロード\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenneizerインスタンスの生成 \n",
    "t = Tokenizer()\n",
    "\n",
    "# テキストを引数として、形態素解析の結果、名詞・動詞原型のみを配列で抽出する関数を定義 \n",
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.base_form for token in tokens \n",
    "        if token.part_of_speech.split(',')[0] in[u'名詞', u'動詞']]\n",
    "\n",
    "#  関数テスト\n",
    "ret = extract_words(u'三四郎は京都でちょっと用があって降りたついでに。')\n",
    "for word in ret:\n",
    "    print word\n",
    "\n",
    "# 全体のテキストを句点(u'。')で区切った配列にする。 \n",
    "sentences = text.split(u'。')\n",
    "# それぞれの文章を単語リストに変換(処理に数分かかります)\n",
    "word_list = [extract_words(sentence) for sentence in sentences]\n",
    "\n",
    "# 結果の一部を確認 \n",
    "for word in word_list[0]:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 準備したデータを用いてWord2Vecのモデル作成、学習実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vecライブラリの導入\n",
    "!pip install gensim  \n",
    "\n",
    "# Word2Vecライブラリのロード\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# size: 圧縮次元数\n",
    "# min_count: 出現頻度の低いものをカットする\n",
    "# window: 前後の単語を拾う際の窓の広さを決める\n",
    "# iter: 機械学習の繰り返し回数(デフォルト:5)十分学習できていないときにこの値を調整する\n",
    "# model.wv.most_similarの結果が1に近いものばかりで、model.dict['wv']のベクトル値が小さい値ばかりの \n",
    "# ときは、学習回数が少ないと考えられます。\n",
    "# その場合、iterの値を大きくして、再度学習を行います。\n",
    "\n",
    "# 事前準備したword_listを使ってWord2Vecの学習実施\n",
    "model = word2vec.Word2Vec(word_list, size=100,min_count=5,window=5,iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の確認1\n",
    "# 一つ一つの単語は100次元のベクトルになっています。 \n",
    "# 「世間」のベクトル値を確認します。\n",
    "print model.__dict__['wv'][u'世間']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の確認2\n",
    "# 関数most_similarを使って「世間」の類似単語を調べます \n",
    "ret = model.wv.most_similar(positive=[u'世間']) \n",
    "for item in ret:\n",
    "    print item[0], item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
